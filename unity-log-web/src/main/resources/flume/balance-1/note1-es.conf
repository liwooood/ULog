note1es.sources = s  
note1es.channels = c  
note1es.sinks = r  

note1es.sources.s.type = org.apache.flume.source.kafka.KafkaSource
note1es.sources.s.zookeeperConnect = 192.168.10.83:2181
note1es.sources.s.topic = ulog
note1es.sources.s.groupId = flume
note1es.sources.s.kafka.consumer.timeout.ms = 100 

note1es.sinks.r.type=org.apache.flume.sink.elasticsearch.ElasticSearchSink
note1es.sinks.r.batchSize=100
note1es.sinks.r.hostNames=192.168.10.83:9300
note1es.sinks.r.indexType = flume_kafka
note1es.sinks.r.indexName=logstash
note1es.sinks.r.clusterName=unifyloggingplatform
note1es.sinks.r.serializer=org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventSerializer  
note1es.sinks.r.indexNameBuilder=org.apache.flume.sink.elasticsearch.SimpleIndexNameBuilder

note1es.channels.c.type = file
note1es.channels.c.checkpointDir = /export/data/flume/flume-1.6.0/dataeckPoint/note1es
note1es.channels.c.useDualCheckpoints = true
note1es.channels.c.backupCheckpointDir = /export/data/flume/flume-1.6.0/data/bakcheckPoint/note1es
note1es.channels.c.dataDirs =/export/data/flume/flume-1.6.0/data/note1es
note1es.channels.c.transactionCapacity = 10000
note1es.channels.c.checkpointInterval = 30000
note1es.channels.c.maxFileSize = 2146435071
note1es.channels.c.minimumRequiredSpace = 524288000
note1es.channels.c.capacity = 1000000

note1es.sources.s.channels = c  
note1es.sinks.r.channel = c 