note2es.sources = s  
note2es.channels = c  
note2es.sinks = r  

note2es.sources.s.type = org.apache.flume.source.kafka.KafkaSource
note2es.sources.s.zookeeperConnect = 192.168.10.83:2181
note2es.sources.s.topic = ulog
note2es.sources.s.groupId = flume
note2es.sources.s.kafka.consumer.timeout.ms = 100 

note2es.sinks.r.type=org.apache.flume.sink.elasticsearch.ElasticSearchSink
note2es.sinks.r.batchSize=100
note2es.sinks.r.hostNames=192.168.10.83:9300
note2es.sinks.r.indexType = flume_kafka
note2es.sinks.r.indexName=logstash
note2es.sinks.r.clusterName=unifyloggingplatform
note2es.sinks.r.serializer=org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventSerializer  
note2es.sinks.r.indexNameBuilder=org.apache.flume.sink.elasticsearch.SimpleIndexNameBuilder

note2es.channels.c.type = file
note2es.channels.c.checkpointDir = /export/data/flume/flume-1.6.0/dataeckPoint/note2es
note2es.channels.c.useDualCheckpoints = true
note2es.channels.c.backupCheckpointDir = /export/data/flume/flume-1.6.0/data/bakcheckPoint/note2es
note2es.channels.c.dataDirs =/export/data/flume/flume-1.6.0/data/note2es
note2es.channels.c.transactionCapacity = 10000
note2es.channels.c.checkpointInterval = 30000
note2es.channels.c.maxFileSize = 2146435071
note2es.channels.c.minimumRequiredSpace = 524288000
note2es.channels.c.capacity = 1000000 

note2es.sources.s.channels = c  
note2es.sinks.r.channel = c 